{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20fc00f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cobra as cb\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dae0ff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROWTH_MIN_OBJ = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4832ced",
   "metadata": {},
   "source": [
    "# Functions for breaking down iiFBA tasks\n",
    "\n",
    "### Functions to clean and streamline\n",
    "- write code for pFBA\n",
    "- write seperate code for Sampling\n",
    "- Write code for iteration\n",
    "- Write code to re-initialize environment\n",
    "  \n",
    "  Lastly:\n",
    "- Write wrapper to run all combined\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e196aec",
   "metadata": {},
   "source": [
    "## pFBA function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b30f8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ii_pfba(model, iter, org_fluxes=None):      \n",
    "    \"\"\"\n",
    "    Summary:\n",
    "    \n",
    "    -------\n",
    "    Params:\n",
    "    - model: cobrapy.Model\n",
    "    \n",
    "    - iter: INT\n",
    "    Numeric indexer for what iteration is being conducted\n",
    "    - org_fluxes: pd.DataFrame\n",
    "    Dataframe class, stores the Iteration Fluxes for the specified \n",
    "    model, for all iterations. \n",
    "\n",
    "    -------\n",
    "    Returns:\n",
    "    - org_fluxes (optional): pd.Dataframe\n",
    "    default = None\n",
    "    Updated fluxes for all reactions in given iteration.\n",
    "\n",
    "    \"\"\"                            \n",
    "    # run pFBA\n",
    "    sol1 = model.slim_optimize()\n",
    "    if sol1 > GROWTH_MIN_OBJ:\n",
    "        sol = cb.flux_analysis.parsimonious.pfba(model)\n",
    "        # standardize and save output                   \n",
    "        df = pd.DataFrame([sol.fluxes],columns=sol.fluxes.index,index=[iter])\n",
    "    else:\n",
    "        rxnid = []\n",
    "        for i in range(len(model.reactions)): \n",
    "            rxnid.append(model.reactions[i].id)\n",
    "        df = pd.DataFrame([np.zeros(len(model.reactions))],columns=rxnid,index=[iter])\n",
    "    \n",
    "    if iter == 0:\n",
    "        org_fluxes = df\n",
    "    else:\n",
    "        org_fluxes = pd.concat([org_fluxes,df])\n",
    "\n",
    "    return org_fluxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1939eb",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1800ebc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ii_sampling(model, iter, run)\n",
    "    # run flux sampling\n",
    "    total_sample_ct = m_vals[0] * m_vals[1]\n",
    "    if iter == 0:\n",
    "        sample_ct = total_sample_ct\n",
    "    else:\n",
    "        sample_ct = m_vals[0]\n",
    "    sol = cb.sampling.sample(model, sample_ct)\n",
    "\n",
    "    # standardize and save output\n",
    "    arrays = [[iter]*total_sample_ct, list(sol.index + m1_idx*m_vals[1])]\n",
    "    tuples = list(zip(*arrays))\n",
    "    multi_idx = pd.MultiIndex.from_tuples(tuples,names=['iteration','run'])\n",
    "    sol.index = multi_idx\n",
    "    F[org_idx] = pd.concat([F[org_idx],sol])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981fe4fc",
   "metadata": {},
   "source": [
    "## Environment Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2ea47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_iifba(models, media, m_vals = None):\n",
    "    # get index type for env. flux log\n",
    "    if m_vals is not None:\n",
    "        # store fluxes of all exchange reactions for the overall model based on media\n",
    "        arrays = [[0]*m_vals[0]*m_vals[1], list(range(m_vals[0]*m_vals[1]))]\n",
    "        tuples = list(zip(*arrays))\n",
    "        index = pd.MultiIndex.from_tuples(tuples,names=['iteration','run'])\n",
    "    else: \n",
    "        index = [0]\n",
    "    \n",
    "    # extract all exchange reactions\n",
    "    cols = set()\n",
    "    for model in models:\n",
    "        for model_ex in range(len(model.exchanges)):\n",
    "            cols.add(model.exchanges[model_ex].id)\n",
    "\n",
    "    # compile initial media conditions\n",
    "    env_fluxes = pd.DataFrame([np.zeros(len(cols))],\n",
    "                     columns=list(cols),\n",
    "                     index=index,dtype=float)\n",
    "    for media_idx in range(len(media)):\n",
    "        exid = media.iloc[media_idx]['Reaction']\n",
    "        ex_flux = media.iloc[media_idx]['LB']\n",
    "        env_fluxes.loc[:,exid] = ex_flux\n",
    "    \n",
    "    # initialize and store organism fluxes\n",
    "    org_rxns = set()\n",
    "    \n",
    "    org_fluxes = pd.DataFrame(np.zeroes)\n",
    "\n",
    "    return env_fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7c57cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_env(model, env_f, iter, run=None):\n",
    "    # reset exchanges\n",
    "    for ex in model.exchanges:\n",
    "        ex.lower_bound = 0\n",
    "        ex.upper_bound = 1000\n",
    "    \n",
    "    # change environment bounds of model\n",
    "    for env_ex in range(len(env_f.columns)):\n",
    "        # run is analog for pfba or sampling and index type & all 0th iter runs have same start env.\n",
    "        index = iter if run is not None else (iter,run if iter != 0 else 0) \n",
    "        ex_lb = env_f.loc[index][env_f.columns[env_ex]]\n",
    "        if ex_lb != 0:\n",
    "            ex_id = env_f.columns[env_ex]\n",
    "            if ex_id in model.exchanges:\n",
    "                model.exchanges.get_by_id(ex_id).lower_bound = ex_lb\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b147cb66",
   "metadata": {},
   "source": [
    "## Env. Flux update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f71182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_flux(models, env_f, org_fluxes, iter, flow, m_vals=None):\n",
    "    sampling_end_ct = 1 if m_vals is None else m_vals[0]*m_vals[1]\n",
    "    for run_idx in range(sampling_end_ct): \n",
    "        index = iter if m_vals is None else (iter,run_idx)\n",
    "        \n",
    "        env_tmp = env_f.loc[[(iter,0)]].copy(deep=True) #temporary dataframe for base environment from iteration\n",
    "        for env_ex in range(len(env_f.columns)):# for each exchange flux in environment\n",
    "            ex_flux_sum = 0\n",
    "            ex_flux_id = env_f.columns[env_ex]\n",
    "            #sum total flux of all bacteria in model\n",
    "            for org_idx, org_model in enumerate(community_model):# for each organism sum up flux * relative abundance\n",
    "                if ex_flux_id in org_model.exchanges:\n",
    "                    if org_fluxes[org_idx].loc[index][ex_flux_id] != 0:\n",
    "                        ex_flux_sum += org_fluxes[org_idx].loc[index][ex_flux_id] * relative_abundance[org_idx]\n",
    "                \n",
    "\n",
    "            #iifba update for ex\n",
    "            env_tmp.loc[index,ex_flux_id] = (1-flow)*(flux_log.loc[(0,0)][ex_flux_id].item()-ex_flux_sum) + flow*flux_log.loc[(0,0)][ex_flux_id].item() # update flux\n",
    "        \n",
    "        #re-index tmp dataframe\n",
    "        multi_idx = pd.MultiIndex.from_tuples([(1,run_idx)],names=[\"iteration\",\"run\"])\n",
    "        df_tt = pd.DataFrame([env_tmp.loc[(0,0)]],columns = env_tmp.columns, index = multi_idx)\n",
    "        flux_log = pd.concat([flux_log,df_tt])\n",
    "\n",
    "\n",
    "        for m2_idx in range(m_vals[1]):\n",
    "            index = iter if solution_type == \"pfba\" else (iter,m2_idx+m1_idx*m_vals[1])\n",
    "            \n",
    "            env_tmp = flux_log.loc[[(iter,M_iter)]].copy(deep=True) #temporary dataframe for base environment from iteration 0,0\n",
    "            for ex_idx in range(len(flux_log.columns)):# for each exchange flux in environment\n",
    "                ex_flux_sum = 0\n",
    "                ex_flux_id = flux_log.columns[ex_idx]\n",
    "                for org_idx in range(len(community_model)):# for each organism sum up flux * relative abundance\n",
    "                    if ex_flux_id in community_model[org_idx].exchanges:\n",
    "                        if F[org_idx].loc[index][ex_flux_id] != 0:\n",
    "                                ex_flux_sum += F[org_idx].loc[index][ex_flux_id] * relative_abundance[org_idx]\n",
    "                            \n",
    "                env_tmp.loc[(iter,M_iter),ex_flux_id] = (1-flow)*(flux_log.loc[(iter,M_iter)][ex_flux_id].item()-ex_flux_sum) + flow*flux_log.loc[(0,0)][ex_flux_id].item() # update flux\n",
    "            #re-index tmp dataframe\n",
    "            multi_idx = pd.MultiIndex.from_tuples([(iter+1,m2_idx+m1_idx*m_vals[1])],names=[\"iteration\",\"run\"])\n",
    "            df_tt = pd.DataFrame([env_tmp.loc[(iter,M_iter)]],columns = env_tmp.columns, index = multi_idx)\n",
    "            flux_log = pd.concat([flux_log,df_tt])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ddb48a",
   "metadata": {},
   "source": [
    "## Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed79cd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iipfba(community_model, media, relative_abundance,\n",
    "          flow=0.5, iterations=10, v=False):\n",
    "    # initialize environmental flux logging\n",
    "    env_f = init_env(community_model, media)\n",
    "\n",
    "    # store organism fluxes here\n",
    "    org_F = [] \n",
    "\n",
    "    # iterations\n",
    "    for iter in range(iterations):\n",
    "        print(\"Iteration\", iter)\n",
    "\n",
    "        for org_model in community_model:\n",
    "            with org_model as model:\n",
    "                # reset exchanges and set env.\n",
    "                model = set_env(model, env_f, iter)\n",
    "\n",
    "                # run optimization\n",
    "                if iter == 0:\n",
    "                    org_F.append(ii_pfba(model, iter))\n",
    "                else:\n",
    "                    org_F[org_idx] = ii_pfba(model, iter, org_F[org_idx])\n",
    "\n",
    "                # flux update\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176203c6",
   "metadata": {},
   "source": [
    "# Test "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f39cc4",
   "metadata": {},
   "source": [
    "#### Original iiFBA function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b464f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple non-sampling\n",
    "def iifba(community_model, media, relative_abundance,\n",
    "          flow=0.5, solution_type=\"pFBA\", \n",
    "          iterations=10,\n",
    "          m_vals=[1,1], v=False):\n",
    "    \"\"\"\n",
    "    Summary:\n",
    "\n",
    "    \n",
    "    Params:\n",
    "    - community_model: LIST type of Cobra Models (len number of unique bacteria)\n",
    "    descr.\n",
    "\n",
    "    - media: pd.DataFrame ()\n",
    "    descr.\n",
    "\n",
    "    - relative_abundance: LIST type of FLOAT (len number of unique bacteria)\n",
    "    relative abundances of each bacteria in community. If sum(relative_abundance) > 1,\n",
    "    relative abundances will be scaled by the sum. \n",
    "\n",
    "    - flow (optional): FLOAT\n",
    "    default = 0.5\n",
    "    Input flow rate of new metabolites/exchanges in media\n",
    "\n",
    "    - solution type (optional): STR\n",
    "    default = \"pFBA\"\n",
    "    Type of optimization for FLux balance\n",
    "    can be \"pFBA\", \"sampling\"\n",
    "\n",
    "    - iterations (optional): INT\n",
    "    default = 10\n",
    "    THe number of interations until completion. Must be greater than 1 iteration.\n",
    "\n",
    "    - m_vals (optional): LIST type of INT (2,)\n",
    "    default = [1, 1]\n",
    "    Number of initial flux points to use in flux sampling and number of runs per \n",
    "    iterations. If both values are 1, then simple 1-to-1 iterations are done.\n",
    "\n",
    "    - v (optional) BOOL\n",
    "    default = False\n",
    "    Turn on verbose or turn off\n",
    "\n",
    "    \n",
    "    Returns:\n",
    "    - flux_log: pandas.Dataframe \n",
    "    Contains values of all fluxes in exchanges of the community. Dataframe is\n",
    "    multi-indexed by (iteration, run), run will always be 0 if using pFBA.\n",
    "\n",
    "    - F: LIST of pandas.Dataframe\n",
    "    Each index of list corresponds to the model of community_model. Each dataframe \n",
    "    contains all the fluxes of the appropriate model. Dataframe is multi-indexed \n",
    "    by (iteration, run), run will always be 0 if using pFBA.\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    # convert all numeric to ints to ensure proper variable useage\n",
    "    m_vals[0] = int(m_vals[0])\n",
    "    m_vals[1] = int(m_vals[1])\n",
    "    iterations = int(iterations)\n",
    "    if solution_type.lower() == \"pfba\":\n",
    "        print(\"Using Parsimonious FBA\")\n",
    "        m_vals = [1,1]\n",
    "    elif solution_type.lower() == \"sampling\":\n",
    "        print(\"Using Flux Sampling\")\n",
    "    else:\n",
    "        print(\"Defaulting to Using Parsimonious FBA\")\n",
    "        solution_type = \"pfba\"\n",
    "    solution_type = solution_type.lower()\n",
    "\n",
    "    if sum(relative_abundance) >1:\n",
    "        print(\"Scaling Abundance\") if v else None\n",
    "        relative_abundance = [r/sum(relative_abundance) for r in relative_abundance]\n",
    "\n",
    "    print(\"Initializing Iterations\") if v else None\n",
    "    M = np.zeros((m_vals[0], iterations -1), dtype=int)\n",
    "    for i in range(iterations-1):\n",
    "        Mcol = np.sort(np.random.choice(m_vals[0]*m_vals[1],m_vals[0],replace=False))\n",
    "        M[:,i]=Mcol\n",
    "        \n",
    "\n",
    "    # store fluxes of all exchange reactions for the overall model based on media\n",
    "    print(\"Initializing Exchanges Logging\") if v else None\n",
    "    arrays = [[0]*m_vals[0]*m_vals[1],list(range(m_vals[0]*m_vals[1]))]\n",
    "    tuples = list(zip(*arrays))\n",
    "    multi_idx = pd.MultiIndex.from_tuples(tuples,names=['iteration','run'])\n",
    "\n",
    "    # extract all exchange reactions\n",
    "    cols = set()\n",
    "    for model_idx in range(len(community_model)):\n",
    "        for model_ex in range(len(community_model[model_idx].exchanges)):\n",
    "            cols.add(community_model[model_idx].exchanges[model_ex].id)\n",
    "\n",
    "    # compile initial media conditions\n",
    "    print(\"Initializing Environment Logging\") if v else None\n",
    "    flux_log = pd.DataFrame([np.zeros(len(cols))],\n",
    "                     columns=list(cols),\n",
    "                     index=multi_idx,dtype=float)\n",
    "    for media_ex in range(len(media)):\n",
    "        exid = media.iloc[media_ex]['Reaction']\n",
    "        ex_flux = media.iloc[media_ex]['LB']\n",
    "        flux_log.loc[:,exid] = ex_flux\n",
    "    \n",
    "    # initialize organism flux dataframes\n",
    "    F = []  \n",
    "\n",
    "    # iterations\n",
    "    print(\"Running Iterations\") if v else None\n",
    "    for iter in range(iterations):\n",
    "        print(\"Iteration:\", iter)\n",
    "        \n",
    "        if iter == 0:\n",
    "            # use media for the first time around for all models\n",
    "            for org_idx in range(len(community_model)):\n",
    "                print(\"Organism:\", org_idx)\n",
    "                with community_model[org_idx] as model_iter:\n",
    "                    # reset exchanges for environment setting\n",
    "                    print(\"Reset Exchanges\") if v else None\n",
    "                    for ex in model_iter.exchanges:\n",
    "                        ex.lower_bound = 0\n",
    "                        ex.upper_bound = 1000\n",
    "                    \n",
    "                    # Set Environment for 0th run (same initial env. for all runs)\n",
    "                    print(\"Set Environment\") if v else None\n",
    "                    for env_ex in range(len(flux_log.columns)):\n",
    "                        ex_lb = flux_log.loc[(0,0)][flux_log.columns[env_ex]] #initial environment is the same for all runs, so use the 0th run\n",
    "                        if ex_lb != 0:\n",
    "                            ex_id = flux_log.columns[env_ex]\n",
    "                            if ex_id in model_iter.exchanges:\n",
    "                                model_iter.exchanges.get_by_id(ex_id).lower_bound = ex_lb\n",
    "                    \n",
    "                    # run optimization with pfba\n",
    "                    if solution_type == 'pfba':\n",
    "                        print(\"Running Optimization\") if v else None\n",
    "                        multi_idx = pd.MultiIndex.from_tuples([(0,0)],names=[\"iteration\",\"run\"])                                       \n",
    "                        # run pFBA\n",
    "                        sol1 = model_iter.slim_optimize()\n",
    "                        if sol1 > 0.001:\n",
    "                            sol = cb.flux_analysis.parsimonious.pfba(model_iter)\n",
    "                            # standardize and save output                   \n",
    "                            df = pd.DataFrame([sol.fluxes],columns=sol.fluxes.index,index=multi_idx)\n",
    "                            F.append(df)\n",
    "                        else:\n",
    "                            # if no growth and cannot use the solution\n",
    "                            rxnid = []\n",
    "                            for i in range(len(model_iter.reactions)): \n",
    "                                rxnid.append(model_iter.reactions[i].id)\n",
    "                            df = pd.DataFrame([np.zeros(len(model_iter.reactions))],columns=rxnid,index=multi_idx)\n",
    "                            F.append(df)\n",
    "                    \n",
    "                    # run optimization with flux sampling\n",
    "                    if solution_type == 'sampling':\n",
    "                        print(\"Running Optimization\") if v else None\n",
    "                        # run flux sampling\n",
    "                        sol = cb.sampling.sample(model_iter, m_vals[0]*m_vals[1])\n",
    "                        # standardize and save output\n",
    "                        arrays = [[0]*m_vals[0]*m_vals[1],list(sol.index)]\n",
    "                        tuples = list(zip(*arrays))\n",
    "                        multi_idx = pd.MultiIndex.from_tuples(tuples,names=['iteration','run'])\n",
    "                        sol.index = multi_idx\n",
    "                        F.append(sol)\n",
    "\n",
    "            # update f\n",
    "            for run_idx in range(m_vals[0]*m_vals[1]): \n",
    "                print(\"Updating Fluxes\") if v else None\n",
    "                env_tmp = flux_log.loc[[(iter,0)]].copy(deep=True) #temporary dataframe for base environment from iteration 0,0\n",
    "                for env_ex in range(len(flux_log.columns)):# for each exchange flux in environment\n",
    "                    ex_flux_sum = 0\n",
    "                    ex_flux_id = flux_log.columns[env_ex]\n",
    "                    #sum total flux of all bacteria in model\n",
    "                    for org_idx in range(len(community_model)):# for each organism sum up flux * relative abundance\n",
    "                        if ex_flux_id in community_model[org_idx].exchanges:\n",
    "                            if F[org_idx].loc[(0,run_idx)][ex_flux_id] != 0:\n",
    "                                ex_flux_sum += F[org_idx].loc[(0,run_idx)][ex_flux_id] * relative_abundance[org_idx]\n",
    "\n",
    "                    #iifba update for ex\n",
    "                    env_tmp.loc[(0,0),ex_flux_id] = (1-flow)*(flux_log.loc[(0,0)][ex_flux_id].item()-ex_flux_sum) + flow*flux_log.loc[(0,0)][ex_flux_id].item() # update flux\n",
    "                \n",
    "                #re-index tmp dataframe\n",
    "                multi_idx = pd.MultiIndex.from_tuples([(1,run_idx)],names=[\"iteration\",\"run\"])\n",
    "                df_tt = pd.DataFrame([env_tmp.loc[(0,0)]],columns = env_tmp.columns, index = multi_idx)\n",
    "                flux_log = pd.concat([flux_log,df_tt])\n",
    "        \n",
    "        # re-run for other iterations\n",
    "        else:       \n",
    "            # if flux sampling, repeat for multiple points\n",
    "            for m1_idx in range(m_vals[0]):\n",
    "                M_iter = M[m1_idx, iter-1]\n",
    "\n",
    "                # run iteration for all bacteria in community\n",
    "                for org_idx in range(len(community_model)):\n",
    "                    print('organism:',org_idx)\n",
    "\n",
    "                    with community_model[org_idx] as model_iter:\n",
    "                        # reset exchanges for environment setting\n",
    "                        print(\"Reset Exchanges\") if v else None\n",
    "                        for ex in model_iter.exchanges:\n",
    "                            ex.lower_bound = 0\n",
    "                            ex.upper_bound = 1000\n",
    "                    \n",
    "                        # Set Environment\n",
    "                        print(\"Set Environment\") if v else None\n",
    "                        for env_ex in range(len(flux_log.columns)):\n",
    "                            ex_lb = flux_log.loc[(iter,M_iter)][flux_log.columns[env_ex]]\n",
    "                            if ex_lb != 0:\n",
    "                                ex_id = flux_log.columns[env_ex]\n",
    "                                if ex_id in model_iter.exchanges:\n",
    "                                    model_iter.exchanges.get_by_id(ex_id).lower_bound = ex_lb\n",
    "                        \n",
    "\n",
    "                        if solution_type == 'pfba':\n",
    "                            print(\"Running Optimization\") if v else None\n",
    "                            multi_idx = pd.MultiIndex.from_tuples([(iter,0)],names=[\"iteration\",\"run\"])                                       \n",
    "                            # run pFBA\n",
    "                            sol1 = model_iter.slim_optimize()\n",
    "                            if sol1 > 0.001:\n",
    "                                sol = cb.flux_analysis.parsimonious.pfba(model_iter)\n",
    "                                # standardize and save output                   \n",
    "                                df = pd.DataFrame([sol.fluxes],columns=sol.fluxes.index,index=multi_idx)\n",
    "                                F[org_idx] = pd.concat([F[org_idx],df])\n",
    "                            else:\n",
    "                                rxnid = []\n",
    "                                for i in range(len(model_iter.reactions)): \n",
    "                                    rxnid.append(model_iter.reactions[i].id)\n",
    "                                df = pd.DataFrame([np.zeros(len(model_iter.reactions))],columns=rxnid,index=multi_idx)\n",
    "                                F[org_idx] = pd.concat([F[org_idx],df])\n",
    "\n",
    "                        if solution_type == 'sampling':\n",
    "                            print(\"Running Optimization\") if v else None\n",
    "                            # run flux sampling\n",
    "                            sol = cb.sampling.sample(model_iter,m_vals[0])\n",
    "                            # standardize and save output\n",
    "                            arrays = [[iter]*m_vals[0]*m_vals[1],list(sol.index+m1_idx*m_vals[1])]\n",
    "                            tuples = list(zip(*arrays))\n",
    "                            multi_idx = pd.MultiIndex.from_tuples(tuples,names=['iteration','run'])\n",
    "                            sol.index = multi_idx\n",
    "                            F[org_idx] = pd.concat([F[org_idx],sol])\n",
    "            \n",
    "            # update fluxes\n",
    "            for m2_idx in range(m_vals[1]):\n",
    "                print(\"Updating Fluxes\") if v else None\n",
    "                env_tmp = flux_log.loc[[(iter,M_iter)]].copy(deep=True) #temporary dataframe for base environment from iteration 0,0\n",
    "                for ex_idx in range(len(flux_log.columns)):# for each exchange flux in environment\n",
    "                    ex_flux_sum = 0\n",
    "                    ex_flux_id = flux_log.columns[ex_idx]\n",
    "                    for org_idx in range(len(community_model)):# for each organism sum up flux * relative abundance\n",
    "                        if ex_flux_id in community_model[org_idx].exchanges:\n",
    "                            if F[org_idx].loc[(iter, m2_idx+m1_idx*m_vals[1])][ex_flux_id] != 0:\n",
    "                                ex_flux_sum += F[org_idx].loc[(iter,m2_idx+m1_idx*m_vals[1])][ex_flux_id] * relative_abundance[org_idx]\n",
    "\n",
    "                    env_tmp.loc[(iter,M_iter),ex_flux_id] = (1-flow)*(flux_log.loc[(iter,M_iter)][ex_flux_id].item()-ex_flux_sum) + flow*flux_log.loc[(0,0)][ex_flux_id].item() # update flux\n",
    "                #re-index tmp dataframe\n",
    "                multi_idx = pd.MultiIndex.from_tuples([(iter+1,m2_idx+m1_idx*m_vals[1])],names=[\"iteration\",\"run\"])\n",
    "                df_tt = pd.DataFrame([env_tmp.loc[(iter,M_iter)]],columns = env_tmp.columns, index = multi_idx)\n",
    "                flux_log = pd.concat([flux_log,df_tt])\n",
    "\n",
    "    return flux_log, F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ccf135",
   "metadata": {},
   "source": [
    "### Test Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38e5bd02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No defined compartments in model model. Compartments will be deduced heuristically using regular expressions.\n",
      "Using regular expression found the following compartments:c, e, p\n"
     ]
    }
   ],
   "source": [
    "# model_pre_processing\n",
    "mod_paths = ['../AGORA2_Models/Escherichia_coli_str_K_12_substr_MG1655.mat']\n",
    "S_matrix = [] #list of models\n",
    "# Load Models and Save in S vector\n",
    "for i in range(len(mod_paths)):\n",
    "    model = cb.io.load_matlab_model(mod_paths[i])\n",
    "    S_matrix.append(model) #append models to list\n",
    "\n",
    "# Define input environment f_0\n",
    "# this should be defined as a pandas dataframe with columns \"Reaction\" and \"LB\"\n",
    "# glucose minimal medium\n",
    "# Define Medium Components\n",
    "glc_min_med = ['EX_glc_D(e)','EX_so4(e)','EX_nh4(e)','EX_no3(e)','EX_pi(e)','EX_cys_L(e)',\n",
    "               'EX_mn2(e)','EX_cl(e)','EX_ca2(e)','EX_mg2(e)','EX_cu2(e)','EX_cobalt2(e)','EX_fe2(e)','EX_fe3(e)','EX_zn2(e)','EX_k(e)']\n",
    "# Define medium uptake flux bounds\n",
    "glc_min_med_flux = [-10,-100,-100,-100,-100,-100,\n",
    "                    -100,-100,-100,-100,-100,-100,-100,-100,-100,-100]\n",
    "glc_f0 = pd.DataFrame(data={'Reaction': glc_min_med,'LB': glc_min_med_flux})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458fd386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple non-sampling\n",
    "def iifba(community_model, media, relative_abundance,\n",
    "          flow=0.5, solution_type=\"pFBA\", \n",
    "          iterations=10,\n",
    "          m_vals=[1,1], v=False):\n",
    "\n",
    "    # convert all numeric to ints to ensure proper variable useage\n",
    "    m_vals[0] = int(m_vals[0])\n",
    "    m_vals[1] = int(m_vals[1])\n",
    "    iterations = int(iterations)\n",
    "    if solution_type.lower() == \"pfba\":\n",
    "        print(\"Using Parsimonious FBA\")\n",
    "        m_vals = [1,1]\n",
    "    elif solution_type.lower() == \"sampling\":\n",
    "        print(\"Using Flux Sampling\")\n",
    "    else:\n",
    "        print(\"Defaulting to Using Parsimonious FBA\")\n",
    "        solution_type = \"pfba\"\n",
    "    solution_type = solution_type.lower()\n",
    "\n",
    "    if sum(relative_abundance) >1:\n",
    "        print(\"Scaling Abundance\") if v else None\n",
    "        relative_abundance = [r/sum(relative_abundance) for r in relative_abundance]\n",
    "\n",
    "    print(\"Initializing Iterations\") if v else None\n",
    "    M = np.zeros((m_vals[0], iterations -1), dtype=int)\n",
    "    for i in range(iterations-1):\n",
    "        Mcol = np.sort(np.random.choice(m_vals[0]*m_vals[1],m_vals[0],replace=False))\n",
    "        M[:,i]=Mcol\n",
    "        \n",
    "\n",
    "    # store fluxes of all exchange reactions for the overall model based on media\n",
    "    print(\"Initializing Exchanges Logging\") if v else None\n",
    "    flux_log = init_env(community_model, media, m_vals=None)\n",
    "    \n",
    "    # initialize organism flux dataframes\n",
    "    F = []  \n",
    "\n",
    "    # iterations\n",
    "    print(\"Running Iterations\") if v else None\n",
    "    for iter in range(iterations):\n",
    "        print(\"Iteration:\", iter)\n",
    "        \n",
    "        if iter == 0:\n",
    "            # use media for the first time around for all models\n",
    "            for org_idx in range(len(community_model)):\n",
    "                print(\"Organism:\", org_idx)\n",
    "                with community_model[org_idx] as model_iter:\n",
    "                    # reset exchanges for environment setting\n",
    "                    print(\"Reset Exchanges\") if v else None\n",
    "                    for ex in model_iter.exchanges:\n",
    "                        ex.lower_bound = 0\n",
    "                        ex.upper_bound = 1000\n",
    "                    \n",
    "                    # Set Environment for 0th run (same initial env. for all runs)\n",
    "                    print(\"Set Environment\") if v else None\n",
    "                    for env_ex in range(len(flux_log.columns)):\n",
    "                        index = 0 if solution_type == \"pfba\" else (0,0)\n",
    "                        ex_lb = flux_log.loc[index][flux_log.columns[env_ex]] #initial environment is the same for all runs, so use the 0th run\n",
    "                        if ex_lb != 0:\n",
    "                            ex_id = flux_log.columns[env_ex]\n",
    "                            if ex_id in model_iter.exchanges:\n",
    "                                model_iter.exchanges.get_by_id(ex_id).lower_bound = ex_lb\n",
    "                    \n",
    "                    # run optimization with pfba\n",
    "                    if solution_type == 'pfba':\n",
    "                        print(\"Running Optimization\") if v else None\n",
    "                        if iter == 0:\n",
    "                            F.append(ii_pfba(model_iter, iter, None ))\n",
    "                        else:\n",
    "                            F[org_idx] = ii_pfba(model_iter, iter, F[org_idx] )\n",
    "                        \n",
    "                    \n",
    "                    # run optimization with flux sampling\n",
    "                    if solution_type == 'sampling':\n",
    "                        print(\"Running Optimization\") if v else None\n",
    "                        # run flux sampling\n",
    "                        sol = cb.sampling.sample(model_iter, m_vals[0]*m_vals[1])\n",
    "                        # standardize and save output\n",
    "                        arrays = [[0]*m_vals[0]*m_vals[1],list(sol.index)]\n",
    "                        tuples = list(zip(*arrays))\n",
    "                        multi_idx = pd.MultiIndex.from_tuples(tuples,names=['iteration','run'])\n",
    "                        sol.index = multi_idx\n",
    "                        F.append(sol)\n",
    "\n",
    "            # update f\n",
    "            for run_idx in range(m_vals[0]*m_vals[1]): \n",
    "                print(\"Updating Fluxes\") if v else None\n",
    "                index = iter if solution_type == \"pfba\" else (iter,run_idx)\n",
    "                env_tmp = flux_log.loc[[(iter,0)]].copy(deep=True) #temporary dataframe for base environment from iteration 0,0\n",
    "                for env_ex in range(len(flux_log.columns)):# for each exchange flux in environment\n",
    "                    ex_flux_sum = 0\n",
    "                    ex_flux_id = flux_log.columns[env_ex]\n",
    "                    #sum total flux of all bacteria in model\n",
    "                    for org_idx in range(len(community_model)):# for each organism sum up flux * relative abundance\n",
    "                        if ex_flux_id in community_model[org_idx].exchanges:\n",
    "                            if F[org_idx].loc[index][ex_flux_id] != 0:\n",
    "                                ex_flux_sum += F[org_idx].loc[0][ex_flux_id] * relative_abundance[org_idx]\n",
    "                        \n",
    "\n",
    "                    #iifba update for ex\n",
    "                    index_2 = \n",
    "                    env_tmp.loc[index,ex_flux_id] = (1-flow)*(flux_log.loc[(0,0)][ex_flux_id].item()-ex_flux_sum) + flow*flux_log.loc[(0,0)][ex_flux_id].item() # update flux\n",
    "                \n",
    "                #re-index tmp dataframe\n",
    "                multi_idx = pd.MultiIndex.from_tuples([(1,run_idx)],names=[\"iteration\",\"run\"])\n",
    "                df_tt = pd.DataFrame([env_tmp.loc[(0,0)]],columns = env_tmp.columns, index = multi_idx)\n",
    "                flux_log = pd.concat([flux_log,df_tt])\n",
    "        \n",
    "        # re-run for other iterations\n",
    "        else:       \n",
    "            # if flux sampling, repeat for multiple points\n",
    "            for m1_idx in range(m_vals[0]):\n",
    "                M_iter = M[m1_idx, iter-1]\n",
    "\n",
    "                # run iteration for all bacteria in community\n",
    "                for org_idx in range(len(community_model)):\n",
    "                    print('organism:',org_idx)\n",
    "\n",
    "                    with community_model[org_idx] as model_iter:\n",
    "                        # reset exchanges for environment setting\n",
    "                        print(\"Reset Exchanges\") if v else None\n",
    "                        for ex in model_iter.exchanges:\n",
    "                            ex.lower_bound = 0\n",
    "                            ex.upper_bound = 1000\n",
    "                    \n",
    "                        # Set Environment\n",
    "                        print(\"Set Environment\") if v else None\n",
    "                        for env_ex in range(len(flux_log.columns)):\n",
    "                            index = iter if solution_type == \"pfba\" else (iter,M_iter)\n",
    "                            ex_lb = flux_log.loc[(iter,M_iter)][flux_log.columns[env_ex]]\n",
    "                            if ex_lb != 0:\n",
    "                                ex_id = flux_log.columns[env_ex]\n",
    "                                if ex_id in model_iter.exchanges:\n",
    "                                    model_iter.exchanges.get_by_id(ex_id).lower_bound = ex_lb\n",
    "                        \n",
    "\n",
    "                        if solution_type == 'pfba':\n",
    "                            print(\"Running Optimization\") if v else None\n",
    "                            if iter == 0:\n",
    "                                F.append(ii_pfba(model_iter, iter, None ))\n",
    "                            else:\n",
    "                                F[org_idx] = ii_pfba(model_iter, iter, F[org_idx] )\n",
    "\n",
    "                        if solution_type == 'sampling':\n",
    "                            print(\"Running Optimization\") if v else None\n",
    "                            # run flux sampling\n",
    "                            sol = cb.sampling.sample(model_iter,m_vals[0])\n",
    "                            # standardize and save output\n",
    "                            arrays = [[iter]*m_vals[0]*m_vals[1],list(sol.index+m1_idx*m_vals[1])]\n",
    "                            tuples = list(zip(*arrays))\n",
    "                            multi_idx = pd.MultiIndex.from_tuples(tuples,names=['iteration','run'])\n",
    "                            sol.index = multi_idx\n",
    "                            F[org_idx] = pd.concat([F[org_idx],sol])\n",
    "            \n",
    "            # update fluxes\n",
    "            for m2_idx in range(m_vals[1]):\n",
    "                print(\"Updating Fluxes\") if v else None\n",
    "                index = iter if solution_type == \"pfba\" else (iter,m2_idx+m1_idx*m_vals[1])\n",
    "                \n",
    "                env_tmp = flux_log.loc[[(iter,M_iter)]].copy(deep=True) #temporary dataframe for base environment from iteration 0,0\n",
    "                for ex_idx in range(len(flux_log.columns)):# for each exchange flux in environment\n",
    "                    ex_flux_sum = 0\n",
    "                    ex_flux_id = flux_log.columns[ex_idx]\n",
    "                    for org_idx in range(len(community_model)):# for each organism sum up flux * relative abundance\n",
    "                        if ex_flux_id in community_model[org_idx].exchanges:\n",
    "                            if F[org_idx].loc[index][ex_flux_id] != 0:\n",
    "                                    ex_flux_sum += F[org_idx].loc[index][ex_flux_id] * relative_abundance[org_idx]\n",
    "                               \n",
    "                                \n",
    "               \n",
    "                    env_tmp.loc[(iter,M_iter),ex_flux_id] = (1-flow)*(flux_log.loc[(iter,M_iter)][ex_flux_id].item()-ex_flux_sum) + flow*flux_log.loc[(0,0)][ex_flux_id].item() # update flux\n",
    "                #re-index tmp dataframe\n",
    "                multi_idx = pd.MultiIndex.from_tuples([(iter+1,m2_idx+m1_idx*m_vals[1])],names=[\"iteration\",\"run\"])\n",
    "                df_tt = pd.DataFrame([env_tmp.loc[(iter,M_iter)]],columns = env_tmp.columns, index = multi_idx)\n",
    "                flux_log = pd.concat([flux_log,df_tt])\n",
    "\n",
    "    return flux_log, F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23cad99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Parsimonious FBA\n",
      "Iteration: 0\n",
      "Organism: 0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index([(0, 0)], dtype='object')] are in the [index]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m f_test, F_test \u001b[38;5;241m=\u001b[39m \u001b[43miifba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mS_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglc_f0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolution_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpFBA\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                  \u001b[49m\u001b[43miterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mm_vals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[33], line 90\u001b[0m, in \u001b[0;36miifba\u001b[0;34m(community_model, media, relative_abundance, flow, solution_type, iterations, m_vals, v)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpdating Fluxes\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     89\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m solution_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpfba\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28miter\u001b[39m,run_idx)\n\u001b[0;32m---> 90\u001b[0m env_tmp \u001b[38;5;241m=\u001b[39m \u001b[43mflux_log\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m#temporary dataframe for base environment from iteration 0,0\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m env_ex \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(flux_log\u001b[38;5;241m.\u001b[39mcolumns)):\u001b[38;5;66;03m# for each exchange flux in environment\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     ex_flux_sum \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/MBE2/lib/python3.10/site-packages/pandas/core/indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[0;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/MBE2/lib/python3.10/site-packages/pandas/core/indexing.py:1420\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1418\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1422\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[1;32m   1423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[0;32m~/anaconda3/envs/MBE2/lib/python3.10/site-packages/pandas/core/indexing.py:1360\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1357\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m   1359\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[0;32m-> 1360\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   1362\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1363\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/MBE2/lib/python3.10/site-packages/pandas/core/indexing.py:1558\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1555\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   1556\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[0;32m-> 1558\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1560\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[0;32m~/anaconda3/envs/MBE2/lib/python3.10/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/MBE2/lib/python3.10/site-packages/pandas/core/indexes/base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[1;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[0;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index([(0, 0)], dtype='object')] are in the [index]\""
     ]
    }
   ],
   "source": [
    "f_test, F_test = iifba(S_matrix, glc_f0, [1],\n",
    "                  flow=0.5, solution_type=\"pFBA\", \n",
    "                  iterations=2,\n",
    "                  m_vals=[1,1], v=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MBE2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
