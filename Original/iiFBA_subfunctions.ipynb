{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20fc00f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cobra as cb\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dae0ff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROWTH_MIN_OBJ = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4832ced",
   "metadata": {},
   "source": [
    "# Functions for breaking down iiFBA tasks\n",
    "\n",
    "### Functions to clean and streamline\n",
    "- write code for pFBA\n",
    "- write seperate code for Sampling\n",
    "- Write code for iteration\n",
    "- Write code to re-initialize environment\n",
    "\t\n",
    "\tLastly:\n",
    "- Write wrapper to run all combined\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e196aec",
   "metadata": {},
   "source": [
    "## pFBA function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b30f8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ii_pfba(model, iter, org_fluxes=None):      \n",
    "\t\"\"\"\n",
    "\tSummary:\n",
    "\t\n",
    "\t-------\n",
    "\tParams:\n",
    "\t- model: cobrapy.Model\n",
    "\t\n",
    "\t- iter: INT\n",
    "\tNumeric indexer for what iteration is being conducted\n",
    "\t- org_fluxes: pd.DataFrame\n",
    "\tDataframe class, stores the Iteration Fluxes for the specified \n",
    "\tmodel, for all iterations. \n",
    "\n",
    "\t-------\n",
    "\tReturns:\n",
    "\t- org_fluxes (optional): pd.Dataframe\n",
    "\tdefault = None\n",
    "\tUpdated fluxes for all reactions in given iteration.\n",
    "\n",
    "\t\"\"\"                            \n",
    "\t# run pFBA\n",
    "\tsol1 = model.slim_optimize()\n",
    "\tif sol1 > GROWTH_MIN_OBJ:\n",
    "\t\tsol = cb.flux_analysis.parsimonious.pfba(model)\n",
    "\t\t# standardize and save output                   \n",
    "\t\tdf = pd.DataFrame([sol.fluxes],columns=sol.fluxes.index,index=[iter])\n",
    "\telse:\n",
    "\t\trxnid = []\n",
    "\t\tfor i in range(len(model.reactions)): \n",
    "\t\t\trxnid.append(model.reactions[i].id)\n",
    "\t\tdf = pd.DataFrame([np.zeros(len(model.reactions))],columns=rxnid,index=[iter])\n",
    "\t\n",
    "\tif iter == 0:\n",
    "\t\torg_fluxes = df\n",
    "\telse:\n",
    "\t\torg_fluxes = pd.concat([org_fluxes,df])\n",
    "\n",
    "\treturn org_fluxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1939eb",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1800ebc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ii_sampling(model, org_fluxes, m_vals, iter, m1_idx):\n",
    "\t# run flux sampling\n",
    "\ttotal_sample_ct = m_vals[0] * m_vals[1]\n",
    "\tsample_ct = total_sample_ct if iter == 0 else m_vals[0]\n",
    "\tsol = cb.sampling.sample(model, sample_ct)\n",
    "\n",
    "\t# standardize and save output\n",
    "\tarrays = [[iter]*total_sample_ct, list(sol.index +  m1_idx*m_vals[1])] # m1_idx is always zero for iter 0\n",
    "\ttuples = list(zip(*arrays))\n",
    "\tmulti_idx = pd.MultiIndex.from_tuples(tuples,names=['iteration','run'])\n",
    "\tsol.index = multi_idx\n",
    "\n",
    "\torg_fluxes = pd.concat([org_fluxes, sol])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981fe4fc",
   "metadata": {},
   "source": [
    "## Environment Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2ea47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_env(models, media, m_vals = None):\n",
    "\t# get index type for env. flux log\n",
    "\tif m_vals is not None:\n",
    "\t\t# store fluxes of all exchange reactions for the overall model based on media\n",
    "\t\tarrays = [[0]*m_vals[0]*m_vals[1], list(range(m_vals[0]*m_vals[1]))]\n",
    "\t\ttuples = list(zip(*arrays))\n",
    "\t\tindex = pd.MultiIndex.from_tuples(tuples,names=['iteration','run'])\n",
    "\telse: \n",
    "\t\tindex = [0]\n",
    "\t\n",
    "\t# extract all exchange reactions\n",
    "\tcols = set()\n",
    "\tfor model in models:\n",
    "\t\tfor model_ex in range(len(model.exchanges)):\n",
    "\t\t\tcols.add(model.exchanges[model_ex].id)\n",
    "\n",
    "\t# compile initial media conditions\n",
    "\tenv_fluxes = pd.DataFrame([np.zeros(len(cols))],\n",
    "\t\t\t\t\t columns=list(cols),\n",
    "\t\t\t\t\t index=index,dtype=float)\n",
    "\tfor media_idx in range(len(media)):\n",
    "\t\texid = media.iloc[media_idx]['Reaction']\n",
    "\t\tex_flux = media.iloc[media_idx]['LB']\n",
    "\t\tenv_fluxes.loc[:,exid] = ex_flux\n",
    "\n",
    "\treturn env_fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7c57cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_env(model, env_f, iter, run=None):\n",
    "\t# reset exchanges\n",
    "\tfor ex in model.exchanges:\n",
    "\t\tex.lower_bound = 0\n",
    "\t\tex.upper_bound = 1000\n",
    "\t\n",
    "\t# change environment bounds of model\n",
    "\tfor env_ex in range(len(env_f.columns)):\n",
    "\t\t# run is analog for pfba or sampling and index type & all 0th iter runs have same start env.\n",
    "\t\tindex = iter if run is None else (iter,run if iter != 0 else 0) \n",
    "\t\tex_lb = env_f.loc[index][env_f.columns[env_ex]].item()\n",
    "\t\tif ex_lb != 0:\n",
    "\t\t\tex_id = env_f.columns[env_ex]\n",
    "\t\t\tif ex_id in model.exchanges:\n",
    "\t\t\t\tmodel.exchanges.get_by_id(ex_id).lower_bound = ex_lb\n",
    "\t\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b147cb66",
   "metadata": {},
   "source": [
    "## Env. Flux update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f71182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_flux(models, env_fluxes, org_fluxes, flow, rel_abund, iter, \n",
    "\t\t\t\tm1_idx=None, M_iter=None, m_vals=None): # sampling specific\n",
    "\t# adjust for sampling\n",
    "\tif m_vals is not None: # sampling\n",
    "\t\tif iter == 0: \n",
    "\t\t\tsampling_end_ct = m_vals[0]*m_vals[1]\n",
    "\t\telse:\n",
    "\t\t\tsampling_end_ct = m_vals[1]\n",
    "\telse: # pFBA\n",
    "\t\tsampling_end_ct = 1\n",
    "\n",
    "\n",
    "\tfor m2_idx in range(sampling_end_ct): \n",
    "\t# condense iter 0 & 1+ and condense pFBA vs sampling \n",
    "\t# caused by indexing\n",
    "\t\tif m_vals is not None:\n",
    "\t\t\tindex = (iter, M_iter)\n",
    "\t\t\tf0_index = (0,0)\n",
    "\t\t\tif iter == 0:\n",
    "\t\t\t\tsumming_idx = (iter, m2_idx)\n",
    "\t\t\t\tnew_index = pd.MultiIndex.from_tuples([(iter+1,M_iter)],names=[\"iteration\",\"run\"])\n",
    "\t\t\telse:\n",
    "\t\t\t\tsumming_idx = (iter, m2_idx + m1_idx * m_vals[1])\n",
    "\t\t\t\tnew_index = pd.MultiIndex.from_tuples([(iter+1,m2_idx + m1_idx*m_vals[1])],names=[\"iteration\",\"run\"])\n",
    "\t\telse:\n",
    "\t\t\tindex = iter\n",
    "\t\t\tf0_index = 0\n",
    "\t\t\tsumming_idx = iter\n",
    "\t\t\tnew_index = [iter+1]\n",
    "\t\t\t\n",
    "\t\t# begin updating fluxes\n",
    "\t\tenv_tmp = env_fluxes.loc[[index]].copy(deep=True) #temporary dataframe for base environment from iteration 0,0\n",
    "\t\tfor ex_idx in range(len(env_tmp.columns)):# for each exchange flux in environment\n",
    "\t\t\tex_flux_sum = 0\n",
    "\t\t\tex_flux_id = env_tmp.columns[ex_idx]\n",
    "\t\t\tfor org_idx, model in enumerate(models):# for each organism sum up flux * relative abundance\n",
    "\t\t\t\tif ex_flux_id in model.exchanges:\n",
    "\t\t\t\t\tif org_fluxes[org_idx].loc[summing_idx][ex_flux_id] != 0:\n",
    "\t\t\t\t\t\tex_flux_sum += org_fluxes[org_idx].loc[summing_idx][ex_flux_id] * rel_abund[org_idx]\n",
    "\t\t\tenv_tmp.loc[index, ex_flux_id] = (1-flow)*(env_tmp.loc[index][ex_flux_id].item()-ex_flux_sum) + flow*env_fluxes.loc[f0_index][ex_flux_id].item() # update flux\n",
    "\t\t\n",
    "\t\t#re-index tmp dataframe & append\n",
    "\t\tdf_tt = pd.DataFrame([env_tmp.loc[index]],columns = env_tmp.columns, index = new_index)\n",
    "\t\tenv_fluxes = pd.concat([env_fluxes,df_tt])\n",
    "\t\t\t\n",
    "\treturn env_fluxes                     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ddb48a",
   "metadata": {},
   "source": [
    "## Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed79cd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iipfba(community_model, media, relative_abundance,\n",
    "\t\t  flow=0.5, iterations=10, v=False):\n",
    "\t# initialize environmental flux logging\n",
    "\tenv_f = init_env(community_model, media)\n",
    "\n",
    "\t# store organism fluxes here\n",
    "\torg_F = [] # use multiindexing with bacteria?\n",
    "\n",
    "\t# iterations\n",
    "\tfor iter in range(iterations):\n",
    "\t\tprint(\"Iteration\", iter)\n",
    "\n",
    "\t\tfor org_idx, org_model in enumerate(community_model):\n",
    "\t\t\twith org_model as model:\n",
    "\t\t\t\t# reset exchanges and set env.\n",
    "\t\t\t\tmodel = set_env(model, env_f, iter)\n",
    "\n",
    "\t\t\t\t# run optimization\n",
    "\t\t\t\tif iter == 0:\n",
    "\t\t\t\t\torg_F.append(ii_pfba(model, iter))\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\torg_F[org_idx] = ii_pfba(model, iter, org_F[org_idx])\n",
    "\n",
    "\t\t\t\t# flux update\n",
    "\t\t\t\tenv_f = update_flux(community_model, env_f, org_F, flow, relative_abundance, iter)\n",
    "\t\t\t\t\n",
    "\treturn env_f, org_F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176203c6",
   "metadata": {},
   "source": [
    "# Test "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f39cc4",
   "metadata": {},
   "source": [
    "#### Original iiFBA function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b464f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple non-sampling\n",
    "def iifba(community_model, media, relative_abundance,\n",
    "\t\t  flow=0.5, solution_type=\"pFBA\", \n",
    "\t\t  iterations=10,\n",
    "\t\t  m_vals=[1,1], v=False):\n",
    "\t\"\"\"\n",
    "\tSummary:\n",
    "\n",
    "\t\n",
    "\tParams:\n",
    "\t- community_model: LIST type of Cobra Models (len number of unique bacteria)\n",
    "\tdescr.\n",
    "\n",
    "\t- media: pd.DataFrame ()\n",
    "\tdescr.\n",
    "\n",
    "\t- relative_abundance: LIST type of FLOAT (len number of unique bacteria)\n",
    "\trelative abundances of each bacteria in community. If sum(relative_abundance) > 1,\n",
    "\trelative abundances will be scaled by the sum. \n",
    "\n",
    "\t- flow (optional): FLOAT\n",
    "\tdefault = 0.5\n",
    "\tInput flow rate of new metabolites/exchanges in media\n",
    "\n",
    "\t- solution type (optional): STR\n",
    "\tdefault = \"pFBA\"\n",
    "\tType of optimization for FLux balance\n",
    "\tcan be \"pFBA\", \"sampling\"\n",
    "\n",
    "\t- iterations (optional): INT\n",
    "\tdefault = 10\n",
    "\tTHe number of interations until completion. Must be greater than 1 iteration.\n",
    "\n",
    "\t- m_vals (optional): LIST type of INT (2,)\n",
    "\tdefault = [1, 1]\n",
    "\tNumber of initial flux points to use in flux sampling and number of runs per \n",
    "\titerations. If both values are 1, then simple 1-to-1 iterations are done.\n",
    "\n",
    "\t- v (optional) BOOL\n",
    "\tdefault = False\n",
    "\tTurn on verbose or turn off\n",
    "\n",
    "\t\n",
    "\tReturns:\n",
    "\t- flux_log: pandas.Dataframe \n",
    "\tContains values of all fluxes in exchanges of the community. Dataframe is\n",
    "\tmulti-indexed by (iteration, run), run will always be 0 if using pFBA.\n",
    "\n",
    "\t- F: LIST of pandas.Dataframe\n",
    "\tEach index of list corresponds to the model of community_model. Each dataframe \n",
    "\tcontains all the fluxes of the appropriate model. Dataframe is multi-indexed \n",
    "\tby (iteration, run), run will always be 0 if using pFBA.\n",
    "\n",
    "\t\n",
    "\t\"\"\"\n",
    "\t# convert all numeric to ints to ensure proper variable useage\n",
    "\tm_vals[0] = int(m_vals[0])\n",
    "\tm_vals[1] = int(m_vals[1])\n",
    "\titerations = int(iterations)\n",
    "\tif solution_type.lower() == \"pfba\":\n",
    "\t\tprint(\"Using Parsimonious FBA\")\n",
    "\t\tm_vals = [1,1]\n",
    "\telif solution_type.lower() == \"sampling\":\n",
    "\t\tprint(\"Using Flux Sampling\")\n",
    "\telse:\n",
    "\t\tprint(\"Defaulting to Using Parsimonious FBA\")\n",
    "\t\tsolution_type = \"pfba\"\n",
    "\tsolution_type = solution_type.lower()\n",
    "\n",
    "\tif sum(relative_abundance) >1:\n",
    "\t\tprint(\"Scaling Abundance\") if v else None\n",
    "\t\trelative_abundance = [r/sum(relative_abundance) for r in relative_abundance]\n",
    "\n",
    "\tprint(\"Initializing Iterations\") if v else None\n",
    "\tM = np.zeros((m_vals[0], iterations -1), dtype=int)\n",
    "\tfor i in range(iterations-1):\n",
    "\t\tMcol = np.sort(np.random.choice(m_vals[0]*m_vals[1],m_vals[0],replace=False))\n",
    "\t\tM[:,i]=Mcol\n",
    "\t\t\n",
    "\n",
    "\t# store fluxes of all exchange reactions for the overall model based on media\n",
    "\tprint(\"Initializing Exchanges Logging\") if v else None\n",
    "\tarrays = [[0]*m_vals[0]*m_vals[1],list(range(m_vals[0]*m_vals[1]))]\n",
    "\ttuples = list(zip(*arrays))\n",
    "\tmulti_idx = pd.MultiIndex.from_tuples(tuples,names=['iteration','run'])\n",
    "\n",
    "\t# extract all exchange reactions\n",
    "\tcols = set()\n",
    "\tfor model_idx in range(len(community_model)):\n",
    "\t\tfor model_ex in range(len(community_model[model_idx].exchanges)):\n",
    "\t\t\tcols.add(community_model[model_idx].exchanges[model_ex].id)\n",
    "\n",
    "\t# compile initial media conditions\n",
    "\tprint(\"Initializing Environment Logging\") if v else None\n",
    "\tflux_log = pd.DataFrame([np.zeros(len(cols))],\n",
    "\t\t\t\t\t columns=list(cols),\n",
    "\t\t\t\t\t index=multi_idx,dtype=float)\n",
    "\tfor media_ex in range(len(media)):\n",
    "\t\texid = media.iloc[media_ex]['Reaction']\n",
    "\t\tex_flux = media.iloc[media_ex]['LB']\n",
    "\t\tflux_log.loc[:,exid] = ex_flux\n",
    "\t\n",
    "\t# initialize organism flux dataframes\n",
    "\tF = []  \n",
    "\n",
    "\t# iterations\n",
    "\tprint(\"Running Iterations\") if v else None\n",
    "\tfor iter in range(iterations):\n",
    "\t\tprint(\"Iteration:\", iter)\n",
    "\t\t\n",
    "\t\tif iter == 0:\n",
    "\t\t\t# use media for the first time around for all models\n",
    "\t\t\tfor org_idx in range(len(community_model)):\n",
    "\t\t\t\tprint(\"Organism:\", org_idx)\n",
    "\t\t\t\twith community_model[org_idx] as model_iter:\n",
    "\t\t\t\t\t# reset exchanges for environment setting\n",
    "\t\t\t\t\tprint(\"Reset Exchanges\") if v else None\n",
    "\t\t\t\t\tfor ex in model_iter.exchanges:\n",
    "\t\t\t\t\t\tex.lower_bound = 0\n",
    "\t\t\t\t\t\tex.upper_bound = 1000\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t# Set Environment for 0th run (same initial env. for all runs)\n",
    "\t\t\t\t\tprint(\"Set Environment\") if v else None\n",
    "\t\t\t\t\tfor env_ex in range(len(flux_log.columns)):\n",
    "\t\t\t\t\t\tex_lb = flux_log.loc[(0,0)][flux_log.columns[env_ex]] #initial environment is the same for all runs, so use the 0th run\n",
    "\t\t\t\t\t\tif ex_lb != 0:\n",
    "\t\t\t\t\t\t\tex_id = flux_log.columns[env_ex]\n",
    "\t\t\t\t\t\t\tif ex_id in model_iter.exchanges:\n",
    "\t\t\t\t\t\t\t\tmodel_iter.exchanges.get_by_id(ex_id).lower_bound = ex_lb\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t# run optimization with pfba\n",
    "\t\t\t\t\tif solution_type == 'pfba':\n",
    "\t\t\t\t\t\tprint(\"Running Optimization\") if v else None\n",
    "\t\t\t\t\t\tmulti_idx = pd.MultiIndex.from_tuples([(0,0)],names=[\"iteration\",\"run\"])                                       \n",
    "\t\t\t\t\t\t# run pFBA\n",
    "\t\t\t\t\t\tsol1 = model_iter.slim_optimize()\n",
    "\t\t\t\t\t\tif sol1 > 0.001:\n",
    "\t\t\t\t\t\t\tsol = cb.flux_analysis.parsimonious.pfba(model_iter)\n",
    "\t\t\t\t\t\t\t# standardize and save output                   \n",
    "\t\t\t\t\t\t\tdf = pd.DataFrame([sol.fluxes],columns=sol.fluxes.index,index=multi_idx)\n",
    "\t\t\t\t\t\t\tF.append(df)\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\t# if no growth and cannot use the solution\n",
    "\t\t\t\t\t\t\trxnid = []\n",
    "\t\t\t\t\t\t\tfor i in range(len(model_iter.reactions)): \n",
    "\t\t\t\t\t\t\t\trxnid.append(model_iter.reactions[i].id)\n",
    "\t\t\t\t\t\t\tdf = pd.DataFrame([np.zeros(len(model_iter.reactions))],columns=rxnid,index=multi_idx)\n",
    "\t\t\t\t\t\t\tF.append(df)\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t# run optimization with flux sampling\n",
    "\t\t\t\t\tif solution_type == 'sampling':\n",
    "\t\t\t\t\t\tprint(\"Running Optimization\") if v else None\n",
    "\t\t\t\t\t\t# run flux sampling\n",
    "\t\t\t\t\t\tsol = cb.sampling.sample(model_iter, m_vals[0]*m_vals[1])\n",
    "\t\t\t\t\t\t# standardize and save output\n",
    "\t\t\t\t\t\tarrays = [[0]*m_vals[0]*m_vals[1],list(sol.index)]\n",
    "\t\t\t\t\t\ttuples = list(zip(*arrays))\n",
    "\t\t\t\t\t\tmulti_idx = pd.MultiIndex.from_tuples(tuples,names=['iteration','run'])\n",
    "\t\t\t\t\t\tsol.index = multi_idx\n",
    "\t\t\t\t\t\tF.append(sol)\n",
    "\n",
    "\t\t\t# update f\n",
    "\t\t\tfor run_idx in range(m_vals[0]*m_vals[1]): \n",
    "\t\t\t\tprint(\"Updating Fluxes\") if v else None\n",
    "\t\t\t\tenv_tmp = flux_log.loc[[(iter,0)]].copy(deep=True) #temporary dataframe for base environment from iteration 0,0\n",
    "\t\t\t\tfor env_ex in range(len(flux_log.columns)):# for each exchange flux in environment\n",
    "\t\t\t\t\tex_flux_sum = 0\n",
    "\t\t\t\t\tex_flux_id = flux_log.columns[env_ex]\n",
    "\t\t\t\t\t#sum total flux of all bacteria in model\n",
    "\t\t\t\t\tfor org_idx in range(len(community_model)):# for each organism sum up flux * relative abundance\n",
    "\t\t\t\t\t\tif ex_flux_id in community_model[org_idx].exchanges:\n",
    "\t\t\t\t\t\t\tif F[org_idx].loc[(0,run_idx)][ex_flux_id] != 0:\n",
    "\t\t\t\t\t\t\t\tex_flux_sum += F[org_idx].loc[(0,run_idx)][ex_flux_id] * relative_abundance[org_idx]\n",
    "\n",
    "\t\t\t\t\t#iifba update for ex\n",
    "\t\t\t\t\tenv_tmp.loc[(0,0),ex_flux_id] = (1-flow)*(flux_log.loc[(0,0)][ex_flux_id].item()-ex_flux_sum) + flow*flux_log.loc[(0,0)][ex_flux_id].item() # update flux\n",
    "\t\t\t\t\n",
    "\t\t\t\t#re-index tmp dataframe\n",
    "\t\t\t\tmulti_idx = pd.MultiIndex.from_tuples([(1,run_idx)],names=[\"iteration\",\"run\"])\n",
    "\t\t\t\tdf_tt = pd.DataFrame([env_tmp.loc[(0,0)]],columns = env_tmp.columns, index = multi_idx)\n",
    "\t\t\t\tflux_log = pd.concat([flux_log,df_tt])\n",
    "\t\t\n",
    "\t\t# re-run for other iterations\n",
    "\t\telse:       \n",
    "\t\t\t# if flux sampling, repeat for multiple points\n",
    "\t\t\tfor m1_idx in range(m_vals[0]):\n",
    "\t\t\t\tM_iter = M[m1_idx, iter-1]\n",
    "\n",
    "\t\t\t\t# run iteration for all bacteria in community\n",
    "\t\t\t\tfor org_idx in range(len(community_model)):\n",
    "\t\t\t\t\tprint('organism:',org_idx)\n",
    "\n",
    "\t\t\t\t\twith community_model[org_idx] as model_iter:\n",
    "\t\t\t\t\t\t# reset exchanges for environment setting\n",
    "\t\t\t\t\t\tprint(\"Reset Exchanges\") if v else None\n",
    "\t\t\t\t\t\tfor ex in model_iter.exchanges:\n",
    "\t\t\t\t\t\t\tex.lower_bound = 0\n",
    "\t\t\t\t\t\t\tex.upper_bound = 1000\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t\t# Set Environment\n",
    "\t\t\t\t\t\tprint(\"Set Environment\") if v else None\n",
    "\t\t\t\t\t\tfor env_ex in range(len(flux_log.columns)):\n",
    "\t\t\t\t\t\t\tex_lb = flux_log.loc[(iter,M_iter)][flux_log.columns[env_ex]]\n",
    "\t\t\t\t\t\t\tif ex_lb != 0:\n",
    "\t\t\t\t\t\t\t\tex_id = flux_log.columns[env_ex]\n",
    "\t\t\t\t\t\t\t\tif ex_id in model_iter.exchanges:\n",
    "\t\t\t\t\t\t\t\t\tmodel_iter.exchanges.get_by_id(ex_id).lower_bound = ex_lb\n",
    "\t\t\t\t\t\t\n",
    "\n",
    "\t\t\t\t\t\tif solution_type == 'pfba':\n",
    "\t\t\t\t\t\t\tprint(\"Running Optimization\") if v else None\n",
    "\t\t\t\t\t\t\tmulti_idx = pd.MultiIndex.from_tuples([(iter,0)],names=[\"iteration\",\"run\"])                                       \n",
    "\t\t\t\t\t\t\t# run pFBA\n",
    "\t\t\t\t\t\t\tsol1 = model_iter.slim_optimize()\n",
    "\t\t\t\t\t\t\tif sol1 > 0.001:\n",
    "\t\t\t\t\t\t\t\tsol = cb.flux_analysis.parsimonious.pfba(model_iter)\n",
    "\t\t\t\t\t\t\t\t# standardize and save output                   \n",
    "\t\t\t\t\t\t\t\tdf = pd.DataFrame([sol.fluxes],columns=sol.fluxes.index,index=multi_idx)\n",
    "\t\t\t\t\t\t\t\tF[org_idx] = pd.concat([F[org_idx],df])\n",
    "\t\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\t\trxnid = []\n",
    "\t\t\t\t\t\t\t\tfor i in range(len(model_iter.reactions)): \n",
    "\t\t\t\t\t\t\t\t\trxnid.append(model_iter.reactions[i].id)\n",
    "\t\t\t\t\t\t\t\tdf = pd.DataFrame([np.zeros(len(model_iter.reactions))],columns=rxnid,index=multi_idx)\n",
    "\t\t\t\t\t\t\t\tF[org_idx] = pd.concat([F[org_idx],df])\n",
    "\n",
    "\t\t\t\t\t\tif solution_type == 'sampling':\n",
    "\t\t\t\t\t\t\tprint(\"Running Optimization\") if v else None\n",
    "\t\t\t\t\t\t\t# run flux sampling\n",
    "\t\t\t\t\t\t\tsol = cb.sampling.sample(model_iter,m_vals[0])\n",
    "\t\t\t\t\t\t\t# standardize and save output\n",
    "\t\t\t\t\t\t\tarrays = [[iter]*m_vals[0]*m_vals[1],list(sol.index+m1_idx*m_vals[1])]\n",
    "\t\t\t\t\t\t\ttuples = list(zip(*arrays))\n",
    "\t\t\t\t\t\t\tmulti_idx = pd.MultiIndex.from_tuples(tuples,names=['iteration','run'])\n",
    "\t\t\t\t\t\t\tsol.index = multi_idx\n",
    "\t\t\t\t\t\t\tF[org_idx] = pd.concat([F[org_idx],sol])\n",
    "\t\t\t\n",
    "\t\t\t# update fluxes\n",
    "\t\t\tfor m2_idx in range(m_vals[1]):\n",
    "\t\t\t\tprint(\"Updating Fluxes\") if v else None\n",
    "\t\t\t\tenv_tmp = flux_log.loc[[(iter,M_iter)]].copy(deep=True) #temporary dataframe for base environment from iteration 0,0\n",
    "\t\t\t\tfor ex_idx in range(len(flux_log.columns)):# for each exchange flux in environment\n",
    "\t\t\t\t\tex_flux_sum = 0\n",
    "\t\t\t\t\tex_flux_id = flux_log.columns[ex_idx]\n",
    "\t\t\t\t\tfor org_idx in range(len(community_model)):# for each organism sum up flux * relative abundance\n",
    "\t\t\t\t\t\tif ex_flux_id in community_model[org_idx].exchanges:\n",
    "\t\t\t\t\t\t\tif F[org_idx].loc[(iter, m2_idx+m1_idx*m_vals[1])][ex_flux_id] != 0:\n",
    "\t\t\t\t\t\t\t\tex_flux_sum += F[org_idx].loc[(iter,m2_idx+m1_idx*m_vals[1])][ex_flux_id] * relative_abundance[org_idx]\n",
    "\n",
    "\t\t\t\t\tenv_tmp.loc[(iter,M_iter),ex_flux_id] = (1-flow)*(flux_log.loc[(iter,M_iter)][ex_flux_id].item()-ex_flux_sum) + flow*flux_log.loc[(0,0)][ex_flux_id].item() # update flux\n",
    "\t\t\t\t#re-index tmp dataframe\n",
    "\t\t\t\tmulti_idx = pd.MultiIndex.from_tuples([(iter+1,m2_idx+m1_idx*m_vals[1])],names=[\"iteration\",\"run\"])\n",
    "\t\t\t\tdf_tt = pd.DataFrame([env_tmp.loc[(iter,M_iter)]],columns = env_tmp.columns, index = multi_idx)\n",
    "\t\t\t\tflux_log = pd.concat([flux_log,df_tt])\n",
    "\n",
    "\treturn flux_log, F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ccf135",
   "metadata": {},
   "source": [
    "### Test Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e5bd02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No defined compartments in model model. Compartments will be deduced heuristically using regular expressions.\n",
      "Using regular expression found the following compartments:c, e, p\n",
      "No defined compartments in model model. Compartments will be deduced heuristically using regular expressions.\n",
      "Using regular expression found the following compartments:c, e, p\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EX_glc_D(e)': -10, 'EX_so4(e)': -100, 'EX_nh4(e)': -100, 'EX_no3(e)': -100, 'EX_pi(e)': -100, 'EX_cys_L(e)': -100, 'EX_mn2(e)': -100, 'EX_cl(e)': -100, 'EX_ca2(e)': -100, 'EX_mg2(e)': -100, 'EX_cu2(e)': -100, 'EX_cobalt2(e)': -100, 'EX_fe2(e)': -100, 'EX_fe3(e)': -100, 'EX_zn2(e)': -100, 'EX_k(e)': -100}\n"
     ]
    }
   ],
   "source": [
    "# model_pre_processing\n",
    "mod_paths = ['../AGORA2_Models/Escherichia_coli_str_K_12_substr_MG1655.mat',\n",
    "\t\t\t \"../AGORA2_Models/Bacteroides_thetaiotaomicron_3731.mat\"]\n",
    "S_matrix = [] #list of models\n",
    "# Load Models and Save in S vector\n",
    "for i in range(len(mod_paths)):\n",
    "\tmodel = cb.io.load_matlab_model(mod_paths[i])\n",
    "\tS_matrix.append(model) #append models to list\n",
    "\n",
    "# Define input environment f_0\n",
    "# this should be defined as a pandas dataframe with columns \"Reaction\" and \"LB\"\n",
    "# glucose minimal medium\n",
    "# Define Medium Components\n",
    "glc_min_med = ['EX_glc_D(e)','EX_so4(e)','EX_nh4(e)','EX_no3(e)','EX_pi(e)','EX_cys_L(e)',\n",
    "\t\t\t   'EX_mn2(e)','EX_cl(e)','EX_ca2(e)','EX_mg2(e)','EX_cu2(e)','EX_cobalt2(e)','EX_fe2(e)','EX_fe3(e)','EX_zn2(e)','EX_k(e)']\n",
    "# Define medium uptake flux bounds\n",
    "glc_min_med_flux = [-10,-100,-100,-100,-100,-100,\n",
    "\t\t\t\t\t-100,-100,-100,-100,-100,-100,-100,-100,-100,-100]\n",
    "\n",
    "glc_f0 = pd.DataFrame(data={'Reaction': glc_min_med,'LB': glc_min_med_flux})\n",
    "glc_f0 = dict(zip(glc_min_med, glc_min_med_flux))\n",
    "print(glc_f0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458fd386",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3708645438.py, line 102)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[41], line 102\u001b[0;36m\u001b[0m\n\u001b[0;31m    index_2 =\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Simple non-sampling\n",
    "def iifba(community_model, media, relative_abundance,\n",
    "\t\t  flow=0.5, solution_type=\"pFBA\", \n",
    "\t\t  iterations=10,\n",
    "\t\t  m_vals=[1,1], v=False):\n",
    "\n",
    "\t# convert all numeric to ints to ensure proper variable useage\n",
    "\tm_vals[0] = int(m_vals[0])\n",
    "\tm_vals[1] = int(m_vals[1])\n",
    "\titerations = int(iterations)\n",
    "\tif solution_type.lower() == \"pfba\":\n",
    "\t\tprint(\"Using Parsimonious FBA\")\n",
    "\t\tm_vals = [1,1]\n",
    "\telif solution_type.lower() == \"sampling\":\n",
    "\t\tprint(\"Using Flux Sampling\")\n",
    "\telse:\n",
    "\t\tprint(\"Defaulting to Using Parsimonious FBA\")\n",
    "\t\tsolution_type = \"pfba\"\n",
    "\tsolution_type = solution_type.lower()\n",
    "\n",
    "\tif sum(relative_abundance) >1:\n",
    "\t\tprint(\"Scaling Abundance\") if v else None\n",
    "\t\trelative_abundance = [r/sum(relative_abundance) for r in relative_abundance]\n",
    "\n",
    "\tprint(\"Initializing Iterations\") if v else None\n",
    "\tM = np.zeros((m_vals[0], iterations), dtype=int)\n",
    "\tfor i in range(iterations-1):\n",
    "\t\tMcol = np.sort(np.random.choice(m_vals[0]*m_vals[1],m_vals[0],replace=False))\n",
    "\t\tM[:,i+1]=Mcol\n",
    "\t\t\n",
    "\n",
    "\t# store fluxes of all exchange reactions for the overall model based on media\n",
    "\tprint(\"Initializing Exchanges Logging\") if v else None\n",
    "\tflux_log = init_env(community_model, media, m_vals=None)\n",
    "\t\n",
    "\t# initialize organism flux dataframes\n",
    "\tF = []  \n",
    "\n",
    "\t# iterations\n",
    "\tprint(\"Running Iterations\") if v else None\n",
    "\tfor iter in range(iterations):\n",
    "\t\tprint(\"Iteration:\", iter)\n",
    "\t\t\n",
    "\t\tif iter == 0:\n",
    "\t\t\t# use media for the first time around for all models\n",
    "\t\t\tfor org_idx in range(len(community_model)):\n",
    "\t\t\t\tprint(\"Organism:\", org_idx)\n",
    "\t\t\t\twith community_model[org_idx] as model_iter:\n",
    "\t\t\t\t\t# reset exchanges for environment setting\n",
    "\t\t\t\t\tprint(\"Reset Exchanges\") if v else None\n",
    "\t\t\t\t\tfor ex in model_iter.exchanges:\n",
    "\t\t\t\t\t\tex.lower_bound = 0\n",
    "\t\t\t\t\t\tex.upper_bound = 1000\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t# Set Environment for 0th run (same initial env. for all runs)\n",
    "\t\t\t\t\tprint(\"Set Environment\") if v else None\n",
    "\t\t\t\t\tfor env_ex in range(len(flux_log.columns)):\n",
    "\t\t\t\t\t\tindex = 0 if solution_type == \"pfba\" else (0,0)\n",
    "\t\t\t\t\t\tex_lb = flux_log.loc[index][flux_log.columns[env_ex]] #initial environment is the same for all runs, so use the 0th run\n",
    "\t\t\t\t\t\tif ex_lb != 0:\n",
    "\t\t\t\t\t\t\tex_id = flux_log.columns[env_ex]\n",
    "\t\t\t\t\t\t\tif ex_id in model_iter.exchanges:\n",
    "\t\t\t\t\t\t\t\tmodel_iter.exchanges.get_by_id(ex_id).lower_bound = ex_lb\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t# run optimization with pfba\n",
    "\t\t\t\t\tif solution_type == 'pfba':\n",
    "\t\t\t\t\t\tprint(\"Running Optimization\") if v else None\n",
    "\t\t\t\t\t\tif iter == 0:\n",
    "\t\t\t\t\t\t\tF.append(ii_pfba(model_iter, iter, None ))\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\tF[org_idx] = ii_pfba(model_iter, iter, F[org_idx] )\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t# run optimization with flux sampling\n",
    "\t\t\t\t\tif solution_type == 'sampling':\n",
    "\t\t\t\t\t\tprint(\"Running Optimization\") if v else None\n",
    "\t\t\t\t\t\t# run flux sampling\n",
    "\t\t\t\t\t\tsol = cb.sampling.sample(model_iter, m_vals[0]*m_vals[1])\n",
    "\t\t\t\t\t\t# standardize and save output\n",
    "\t\t\t\t\t\tarrays = [[0]*m_vals[0]*m_vals[1],list(sol.index)]\n",
    "\t\t\t\t\t\ttuples = list(zip(*arrays))\n",
    "\t\t\t\t\t\tmulti_idx = pd.MultiIndex.from_tuples(tuples,names=['iteration','run'])\n",
    "\t\t\t\t\t\tsol.index = multi_idx\n",
    "\t\t\t\t\t\tF.append(sol)\n",
    "\n",
    "\t\t\t# update f\n",
    "\t\t\tfor run_idx in range(m_vals[0]*m_vals[1]): \n",
    "\t\t\t\tprint(\"Updating Fluxes\") if v else None\n",
    "\t\t\t\tindex = iter if solution_type == \"pfba\" else (iter,run_idx)\n",
    "\t\t\t\tenv_tmp = flux_log.loc[[(iter,0)]].copy(deep=True) #temporary dataframe for base environment from iteration 0,0\n",
    "\t\t\t\tfor env_ex in range(len(flux_log.columns)):# for each exchange flux in environment\n",
    "\t\t\t\t\tex_flux_sum = 0\n",
    "\t\t\t\t\tex_flux_id = flux_log.columns[env_ex]\n",
    "\t\t\t\t\t#sum total flux of all bacteria in model\n",
    "\t\t\t\t\tfor org_idx in range(len(community_model)):# for each organism sum up flux * relative abundance\n",
    "\t\t\t\t\t\tif ex_flux_id in community_model[org_idx].exchanges:\n",
    "\t\t\t\t\t\t\tif F[org_idx].loc[index][ex_flux_id] != 0:\n",
    "\t\t\t\t\t\t\t\tex_flux_sum += F[org_idx].loc[0][ex_flux_id] * relative_abundance[org_idx]\n",
    "\t\t\t\t\t\t\n",
    "\n",
    "\t\t\t\t\t#iifba update for ex\n",
    "\t\t\t\t\tindex_2 = \n",
    "\t\t\t\t\tenv_tmp.loc[index,ex_flux_id] = (1-flow)*(flux_log.loc[(0,0)][ex_flux_id].item()-ex_flux_sum) + flow*flux_log.loc[(0,0)][ex_flux_id].item() # update flux\n",
    "\t\t\t\t\n",
    "\t\t\t\t#re-index tmp dataframe\n",
    "\t\t\t\tmulti_idx = pd.MultiIndex.from_tuples([(1,run_idx)],names=[\"iteration\",\"run\"])\n",
    "\t\t\t\tdf_tt = pd.DataFrame([env_tmp.loc[(0,0)]],columns = env_tmp.columns, index = multi_idx)\n",
    "\t\t\t\tflux_log = pd.concat([flux_log,df_tt])\n",
    "\t\t\n",
    "\t\t# re-run for other iterations\n",
    "\t\telse:       \n",
    "\t\t\t# if flux sampling, repeat for multiple points\n",
    "\t\t\tfor m1_idx in range(m_vals[0]):\n",
    "\t\t\t\tM_iter = M[m1_idx, iter-1]\n",
    "\n",
    "\t\t\t\t# run iteration for all bacteria in community\n",
    "\t\t\t\tfor org_idx in range(len(community_model)):\n",
    "\t\t\t\t\tprint('organism:',org_idx)\n",
    "\n",
    "\t\t\t\t\twith community_model[org_idx] as model_iter:\n",
    "\t\t\t\t\t\t# reset exchanges for environment setting\n",
    "\t\t\t\t\t\tprint(\"Reset Exchanges\") if v else None\n",
    "\t\t\t\t\t\tfor ex in model_iter.exchanges:\n",
    "\t\t\t\t\t\t\tex.lower_bound = 0\n",
    "\t\t\t\t\t\t\tex.upper_bound = 1000\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t\t# Set Environment\n",
    "\t\t\t\t\t\tprint(\"Set Environment\") if v else None\n",
    "\t\t\t\t\t\tfor env_ex in range(len(flux_log.columns)):\n",
    "\t\t\t\t\t\t\tindex = iter if solution_type == \"pfba\" else (iter,M_iter)\n",
    "\t\t\t\t\t\t\tex_lb = flux_log.loc[(iter,M_iter)][flux_log.columns[env_ex]]\n",
    "\t\t\t\t\t\t\tif ex_lb != 0:\n",
    "\t\t\t\t\t\t\t\tex_id = flux_log.columns[env_ex]\n",
    "\t\t\t\t\t\t\t\tif ex_id in model_iter.exchanges:\n",
    "\t\t\t\t\t\t\t\t\tmodel_iter.exchanges.get_by_id(ex_id).lower_bound = ex_lb\n",
    "\t\t\t\t\t\t\n",
    "\n",
    "\t\t\t\t\t\tif solution_type == 'pfba':\n",
    "\t\t\t\t\t\t\tprint(\"Running Optimization\") if v else None\n",
    "\t\t\t\t\t\t\tif iter == 0:\n",
    "\t\t\t\t\t\t\t\tF.append(ii_pfba(model_iter, iter, None ))\n",
    "\t\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\t\tF[org_idx] = ii_pfba(model_iter, iter, F[org_idx] )\n",
    "\n",
    "\t\t\t\t\t\tif solution_type == 'sampling':\n",
    "\t\t\t\t\t\t\tprint(\"Running Optimization\") if v else None\n",
    "\t\t\t\t\t\t\t# run flux sampling\n",
    "\t\t\t\t\t\t\tsol = cb.sampling.sample(model_iter,m_vals[0])\n",
    "\t\t\t\t\t\t\t# standardize and save output\n",
    "\t\t\t\t\t\t\tarrays = [[iter]*m_vals[0]*m_vals[1],list(sol.index+m1_idx*m_vals[1])]\n",
    "\t\t\t\t\t\t\ttuples = list(zip(*arrays))\n",
    "\t\t\t\t\t\t\tmulti_idx = pd.MultiIndex.from_tuples(tuples,names=['iteration','run'])\n",
    "\t\t\t\t\t\t\tsol.index = multi_idx\n",
    "\t\t\t\t\t\t\tF[org_idx] = pd.concat([F[org_idx],sol])\n",
    "\t\t\t\n",
    "\t\t\t# update fluxes\n",
    "\t\t\tfor m2_idx in range(m_vals[1]):\n",
    "\t\t\t\tprint(\"Updating Fluxes\") if v else None\n",
    "\t\t\t\tindex = iter if solution_type == \"pfba\" else (iter,m2_idx+m1_idx*m_vals[1])\n",
    "\t\t\t\t\n",
    "\t\t\t\tenv_tmp = flux_log.loc[[(iter,M_iter)]].copy(deep=True) #temporary dataframe for base environment from iteration 0,0\n",
    "\t\t\t\tfor ex_idx in range(len(flux_log.columns)):# for each exchange flux in environment\n",
    "\t\t\t\t\tex_flux_sum = 0\n",
    "\t\t\t\t\tex_flux_id = flux_log.columns[ex_idx]\n",
    "\t\t\t\t\tfor org_idx in range(len(community_model)):# for each organism sum up flux * relative abundance\n",
    "\t\t\t\t\t\tif ex_flux_id in community_model[org_idx].exchanges:\n",
    "\t\t\t\t\t\t\tif F[org_idx].loc[index][ex_flux_id] != 0:\n",
    "\t\t\t\t\t\t\t\t\tex_flux_sum += F[org_idx].loc[index][ex_flux_id] * relative_abundance[org_idx]\n",
    "\t\t\t\t\t\t\t   \n",
    "\t\t\t\t\t\t\t\t\n",
    "\t\t\t   \n",
    "\t\t\t\t\tenv_tmp.loc[(iter,M_iter),ex_flux_id] = (1-flow)*(flux_log.loc[(iter,M_iter)][ex_flux_id].item()-ex_flux_sum) + flow*flux_log.loc[(0,0)][ex_flux_id].item() # update flux\n",
    "\t\t\t\t#re-index tmp dataframe\n",
    "\t\t\t\tmulti_idx = pd.MultiIndex.from_tuples([(iter+1,m2_idx+m1_idx*m_vals[1])],names=[\"iteration\",\"run\"])\n",
    "\t\t\t\tdf_tt = pd.DataFrame([env_tmp.loc[(iter,M_iter)]],columns = env_tmp.columns, index = multi_idx)\n",
    "\t\t\t\tflux_log = pd.concat([flux_log,df_tt])\n",
    "\n",
    "\treturn flux_log, F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cad99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Parsimonious FBA\n",
      "Iteration: 0\n",
      "Organism: 0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index([(0, 0)], dtype='object')] are in the [index]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m f_test, F_test \u001b[38;5;241m=\u001b[39m \u001b[43miifba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mS_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglc_f0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolution_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpFBA\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                  \u001b[49m\u001b[43miterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mm_vals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[33], line 90\u001b[0m, in \u001b[0;36miifba\u001b[0;34m(community_model, media, relative_abundance, flow, solution_type, iterations, m_vals, v)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpdating Fluxes\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     89\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m solution_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpfba\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28miter\u001b[39m,run_idx)\n\u001b[0;32m---> 90\u001b[0m env_tmp \u001b[38;5;241m=\u001b[39m \u001b[43mflux_log\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m#temporary dataframe for base environment from iteration 0,0\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m env_ex \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(flux_log\u001b[38;5;241m.\u001b[39mcolumns)):\u001b[38;5;66;03m# for each exchange flux in environment\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     ex_flux_sum \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/MBE2/lib/python3.10/site-packages/pandas/core/indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[0;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/MBE2/lib/python3.10/site-packages/pandas/core/indexing.py:1420\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1418\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1422\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[1;32m   1423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[0;32m~/anaconda3/envs/MBE2/lib/python3.10/site-packages/pandas/core/indexing.py:1360\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1357\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m   1359\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[0;32m-> 1360\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   1362\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1363\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/MBE2/lib/python3.10/site-packages/pandas/core/indexing.py:1558\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1555\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   1556\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[0;32m-> 1558\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1560\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[0;32m~/anaconda3/envs/MBE2/lib/python3.10/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/MBE2/lib/python3.10/site-packages/pandas/core/indexes/base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[1;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[0;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index([(0, 0)], dtype='object')] are in the [index]\""
     ]
    }
   ],
   "source": [
    "f_test, F_test = iifba(S_matrix, glc_f0, [1],\n",
    "\t\t\t\t  flow=0.5, solution_type=\"pFBA\", \n",
    "\t\t\t\t  iterations=2,\n",
    "\t\t\t\t  m_vals=[1,1], v=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba36da78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n"
     ]
    }
   ],
   "source": [
    "f, F = iipfba(S_matrix, glc_f0, [0.5, 0.5], flow=0.49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25f854ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.784637\n",
       "1    0.588478\n",
       "2    0.539438\n",
       "3    0.527178\n",
       "4    0.524113\n",
       "5    0.523347\n",
       "6    0.523155\n",
       "7    0.523107\n",
       "8    0.523095\n",
       "9    0.523092\n",
       "Name: biomass525, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F[0][\"biomass525\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a5964e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.784637\n",
       "1    0.584555\n",
       "2    0.533534\n",
       "3    0.520523\n",
       "4    0.517206\n",
       "5    0.516360\n",
       "6    0.516144\n",
       "7    0.516089\n",
       "8    0.516075\n",
       "9    0.516071\n",
       "Name: biomass525, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F[0][\"biomass525\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36af346a",
   "metadata": {},
   "source": [
    "# Lin. Alg. Based Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74250edc",
   "metadata": {},
   "source": [
    "## Environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266c5cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_iifba(models, media, iterations, m_vals=[1,1]):\n",
    "\t# get list of all unique rxns and exchanges\n",
    "\torg_exs = set()\n",
    "\torg_rxns = set()\n",
    "\tfor model in models:\n",
    "\t\texs_set = set(model.exchanges.list_attr(\"id\"))\n",
    "\t\torg_exs = org_exs | exs_set # exchanges\n",
    "\t\trxns_set = set(model.reactions.list_attr(\"id\"))\n",
    "\t\torg_rxns = org_rxns | rxns_set # reactions\n",
    "\n",
    "\t# initialize env\n",
    "\trows = (iterations) * m_vals[0] * m_vals[1] + 1 # add one iteration for final env\n",
    "\tcols = len(org_exs)\n",
    "\tenv_f = np.zeros((rows, cols))\n",
    "\tenv0_masks = [np.array(list(org_exs)) == rxn_id for rxn_id in list(media.keys()) ]\n",
    "\tfor flux_idx, flux in enumerate(list(media.values())):\n",
    "\t\tenv_f[0][env0_masks[flux_idx]] = flux\n",
    "\t\n",
    "\t#set columns for multi-indexing\n",
    "\titers_col = np.repeat(np.arange(1, iterations+1), m_vals[0] * m_vals[1]) \n",
    "\trun_col = np.tile(np.arange(m_vals[0] * m_vals[1]), iterations)\n",
    "\titers_col = np.insert(iters_col, 0, 0) # add 0th iteration\n",
    "\trun_col = np.insert(run_col, 0, 0) # add 0th run \n",
    "\tmulti_idx = [iters_col , run_col]\n",
    "\tenv_f = pd.DataFrame(env_f, columns=list(org_exs), index=multi_idx) # convert to interprettable df\n",
    "\tenv_f.index.names = [\"Iteration\", \"Run\"]\n",
    "\n",
    "\t# initialize org_fluxes\n",
    "\trows = iterations * m_vals[0] * m_vals[1] * len(models)\n",
    "\tcols = len(org_rxns)\n",
    "\torg_F = np.zeros((rows, cols)) # pfba will drop run column\n",
    "\t\n",
    "\t# create unique multi-index for \n",
    "\tmodels_col = np.tile(np.arange(len(models)), iterations * m_vals[0] * m_vals[1]) \n",
    "\titers_col = np.repeat(np.arange(iterations), m_vals[0] * m_vals[1] * len(models)) \n",
    "\trun_col = np.tile(np.repeat(np.arange(m_vals[0] * m_vals[1]), len(models)), iterations) \n",
    "\tmulti_idx = [models_col, iters_col , run_col]\n",
    "\torg_F = pd.DataFrame(org_F, columns=list(org_rxns), index=multi_idx)\t# convert to interprettable df\n",
    "\torg_F.index.names = [\"model\", \"Iteration\", \"Run\"]\n",
    "\t\n",
    "\treturn env_f, org_F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c46f5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_env(model, env_f, iter, run):\n",
    "\tfor ex in model.exchanges:\n",
    "\t\tex.lower_bound = env_f.loc[iter, run][ex.id]\n",
    "\t\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50afca86",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa9cc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pfba(model, model_idx, iter, org_F):\n",
    "\t# run pFBA\n",
    "\tsol1 = model.slim_optimize()\n",
    "\tif sol1 > GROWTH_MIN_OBJ:\n",
    "\t\tsol = cb.flux_analysis.parsimonious.pfba(model)\n",
    "\t\t\n",
    "\t\torg_F.loc[(model_idx, iter, 0), list(sol.fluxes.index)] = sol.fluxes.values\n",
    "\t# do nothing otherwise - already initiated as zeros!\n",
    "\n",
    "\treturn org_F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "22cff4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sampling(model, model_idx, iter, org_F, m_vals, rep_idx):\n",
    "\t# run flux sampling\n",
    "\tif iter == 0:\n",
    "\t\tsample_ct = m_vals[0] * m_vals[1]\n",
    "\telse:\n",
    "\t\tsample_ct = m_vals[1]\n",
    "\tsol = cb.sampling.sample(model, sample_ct)\n",
    "\t\n",
    "\t# standardize and save output\n",
    "\tarrays = [[model_idx] * sample_ct, [iter] * sample_ct, list(sol.index + rep_idx * sample_ct)]\n",
    "\ttuples = list(zip(*arrays))\n",
    "\tmulti_idx = pd.MultiIndex.from_tuples(tuples, names=['model', 'Iteration', 'Run'])\n",
    "\tsol.index = multi_idx\n",
    "\t\n",
    "\torg_F.loc[sol.index, sol.columns] = sol\n",
    "\n",
    "\treturn org_F\n",
    "\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04255018",
   "metadata": {},
   "source": [
    "## Flux Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e29adc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_pfba_env(env_f, org_F, flow, rel_abund, iter):\n",
    "\t# get initial env. for flow\n",
    "\tinit_env = env_f.loc[0,0].to_numpy()\n",
    "\t#pull iter info\n",
    "\tenv_tmp = env_f.loc[iter, 0][:].to_numpy()\n",
    "\trun_exs = org_F.loc[:, iter, 0][env_f.columns].to_numpy()\n",
    "\t\t\n",
    "\t# run update\n",
    "\tflux_sums = (run_exs.T @ rel_abund).flatten()\n",
    "\tenv_f.loc[iter+1, 0] = (1-flow)*(env_tmp - flux_sums) + flow*init_env\n",
    "\t\n",
    "\treturn env_f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ca94e8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_sampling_env(env_f, org_F, flow, rel_abund, iter, m_vals, Mi, rep_idx):\n",
    "\t# get initial env. for flow\n",
    "\tinit_env = env_f.loc[(0,0)].to_numpy()\n",
    "\n",
    "\tsample_ct = m_vals[0] * m_vals[1] if iter == 0 else m_vals[1]\n",
    "\tfor sample_idx in range(sample_ct):\n",
    "\t\t#pull run info\n",
    "\t\tenv_tmp = env_f.loc[iter, Mi][:].to_numpy()\n",
    "\t\trun_exs = org_F.loc[:, iter, Mi][env_f.columns].to_numpy()\n",
    "\n",
    "\t\t# run update\n",
    "\t\tflux_sums = (run_exs.T @ rel_abund).flatten()\n",
    "\t\tenv_f.loc[iter+1, sample_idx+ m_vals[1]*rep_idx] = (1-flow)*(env_tmp - flux_sums) + flow*init_env\n",
    "\n",
    "\treturn env_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fbe9759c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 7\n",
      "Iteration: 8\n",
      "Iteration: 9\n"
     ]
    }
   ],
   "source": [
    "f, F = iipfba(S_matrix, glc_f0, np.array([0.5, 0.5]).reshape((-1,1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69d0c7a",
   "metadata": {},
   "source": [
    "## Wrapper Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69810e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iipfba(models, media, rel_abund,\n",
    "\t\t   iters=10, flow=0.5):\n",
    "\tenv_fluxes, org_fluxes = init_iifba(models, media, iters)\n",
    "\n",
    "\tfor iter in range(iters):\n",
    "\t\tprint(\"Iteration:\", iter)\n",
    "\n",
    "\t\tfor org_idx, org_model in enumerate(models):\n",
    "\t\t\twith org_model as model:\n",
    "\t\t\t\t# set exchanges\n",
    "\t\t\t\tmodel = set_env(model, env_fluxes, iter, 0) # only 0 runs\n",
    "\n",
    "\t\t\t\t# run optim\n",
    "\t\t\t\torg_fluxes = run_pfba(model, org_idx, iter, org_fluxes)\n",
    "\t\t\t\t\n",
    "\t\t# update fluxes\n",
    "\t\tenv_fluxes = update_pfba_env(env_fluxes, org_fluxes, flow, rel_abund, iter)\n",
    "\n",
    "\t# pfba has no use for Run index\n",
    "\tenv_fluxes = env_fluxes.droplevel(\"Run\")\n",
    "\torg_fluxes =org_fluxes.droplevel(\"Run\")\n",
    "\n",
    "\treturn env_fluxes, org_fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7ea13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iisampling(models, media, rel_abund, iters=10, flow=0.5, m_vals=[1,1]):\n",
    "\t# mapping of what flux sampling to iterate\n",
    "\tM = np.zeros([m_vals[0],iters],dtype=int) #randomly pre-assign sampling initial point matrix\n",
    "\tfor i in range(1, iters):\n",
    "\t\tMcol = np.sort(np.random.choice(m_vals[0]*m_vals[1],m_vals[0],replace=False))\n",
    "\t\tM[:,i]=Mcol\n",
    "\tprint(M)\n",
    "\n",
    "\t# initialize env and org fluxes\n",
    "\tenv_fluxes, org_fluxes = init_iifba(models, media, iters, m_vals)\n",
    "\n",
    "\tfor iter in range(iters):\n",
    "\t\tprint(\"Iteration:\", iter)\n",
    "\n",
    "\t\t# number of times to re-sample per iteration\n",
    "\t\trepeat_ct = 1 if iter == 0 else m_vals[0] \n",
    "\t\tfor rep_idx in range(repeat_ct):\n",
    "\t\t\tMi = M[rep_idx, iter]\n",
    "\n",
    "\t\t\t# samples taken\n",
    "\t\t\tsamples = m_vals[0] * m_vals[1] if iter == 0 else m_vals[1]\n",
    "\t\t\tfor org_idx, org_model in enumerate(models):\n",
    "\t\t\t\twith org_model as model:\n",
    "\t\t\t\t\t# set exchanges\n",
    "\t\t\t\t\tmodel = set_env(model, env_fluxes, iter, Mi)\n",
    "\n",
    "\t\t\t\t\t# run optim\n",
    "\t\t\t\t\torg_fluxes = run_sampling(model, org_idx, iter, org_fluxes, m_vals, rep_idx=rep_idx)\n",
    "\t\t\t\t\n",
    "\t\t# update fluxes\n",
    "\t\tenv_fluxes = update_sampling_env(env_fluxes, org_fluxes, flow, rel_abund, iter, m_vals, Mi, rep_idx)\n",
    "\n",
    "\n",
    "\treturn env_fluxes, org_fluxes, M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "40e078b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  3  3  0  0  0 21  8  7  4]\n",
      " [ 0 16  5 10  2  1 27 26 12  5]\n",
      " [ 0 27 10 16  4 21 33 67 37 17]\n",
      " [ 0 32 12 18 23 30 38 69 38 20]\n",
      " [ 0 58 14 28 30 38 42 73 39 30]\n",
      " [ 0 60 23 40 44 45 49 77 50 31]\n",
      " [ 0 78 28 49 50 65 53 84 77 48]\n",
      " [ 0 79 46 76 72 68 64 86 84 49]\n",
      " [ 0 82 80 87 75 77 90 97 87 55]\n",
      " [ 0 90 88 94 78 92 92 98 91 61]]\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 7\n",
      "Iteration: 8\n",
      "Iteration: 9\n"
     ]
    }
   ],
   "source": [
    "f, F = iisampling(S_matrix, glc_f0, np.array([0.5, 0.5]).reshape((-1,1)), \n",
    "\t\t\t\t  iters=10, flow=0.49, m_vals=[10,10])\n",
    "\n",
    "# print((f.loc[0,:].to_numpy()).sum(axis=1))\n",
    "# print(f)\n",
    "# print(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5cb6b1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  Run\n",
      "0          0      1.482879e-04\n",
      "           1      1.428481e-04\n",
      "           2      1.731319e-05\n",
      "           3      4.165337e-04\n",
      "           4      4.924318e-04\n",
      "                      ...     \n",
      "9          95     1.902370e-14\n",
      "           96    -1.326598e-14\n",
      "           97    -1.258432e-14\n",
      "           98    -1.761411e-14\n",
      "           99    -2.616479e-14\n",
      "Name: biomass525, Length: 1000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(F.loc[0,: ,:][\"biomass525\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "6c650651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration\n",
      "0    0.784637\n",
      "1    0.505684\n",
      "2    0.472349\n",
      "3    0.465576\n",
      "4    0.464291\n",
      "5    0.463970\n",
      "6    0.463890\n",
      "7    0.463870\n",
      "8    0.463865\n",
      "9    0.463863\n",
      "Name: biomass525, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(F.loc[0, :][\"biomass525\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MBE2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
